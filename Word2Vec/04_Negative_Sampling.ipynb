{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 분류에서 이진 분류로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Embedding\n",
    "# nn_layers.py에 추가하여 놓는다\n",
    "class Embedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.idx = None\n",
    "        \n",
    "    # 순전파    \n",
    "    def forward(self, idx):\n",
    "        W, = self.params\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "    \n",
    "    # 속도가 향상됨\n",
    "    def backward(self, dout):\n",
    "        dW, = self.grads\n",
    "        dW[...] = 0\n",
    "        np.add.at(dW, self.idx, dout)  \n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_layers.py에 추가하여 놓는다\n",
    "class EmbeddingDot:\n",
    "    def __init__(self, W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, h, idx):\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W * h, axis=1)\n",
    "\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):  \n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0], 1) # \n",
    "\n",
    "        dtarget_W = dout * h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout * target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:\n",
      " [[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]\n",
      " [18 19 20]]\n",
      "idx:\n",
      " [[0 3 1]]\n",
      "h:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "target_W:\n",
      " [[ 0  1  2]\n",
      " [ 9 10 11]\n",
      " [ 3  4  5]]\n",
      "target_W*h:\n",
      " [[ 0  1  4]\n",
      " [27 40 55]\n",
      " [18 28 40]]\n",
      "out:\n",
      " [  5 122  86]\n"
     ]
    }
   ],
   "source": [
    "# EmbeddingDot 내의 forward 함수내에서 변수의 값 변화 정보\n",
    "W = np.arange(21).reshape(7,3)\n",
    "print('W:\\n',W)\n",
    "idx = np.array([[0,3,1]])\n",
    "print('idx:\\n',idx)\n",
    "h = W[[0,1,2]]\n",
    "print('h:\\n',h)\n",
    "embed = Embedding(W)\n",
    "target_W = embed.forward(idx)\n",
    "print('target_W:\\n',target_W.reshape(-1,3))\n",
    "print('target_W*h:\\n',target_W.reshape(-1,3)*h)\n",
    "out = np.sum(target_W.reshape(-1,3)*h, axis=1)  # 수평방향 합\n",
    "print('out:\\n',out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네거티브 샘플링의 샘플링 기법\n",
    "\n",
    "https://ddiri01.tistory.com/310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 0에서 9가지의 숫자 중 하나를 무작위로  샘플링\n",
    "np.random.choice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words에서 하나만 무작위로  샘플링\n",
    "words = ['you','say','goodbye','I','hello','.']\n",
    "np.random.choice(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'say', 'say', '.', 'I'], dtype='<U7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개만 무작위로 샘플링(중복 허용)\n",
    "np.random.choice(words, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', '.', 'hello', 'say', 'goodbye'], dtype='<U7')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개만 무작위로 샘플링(중복 금지)\n",
    "np.random.choice(words, size=5, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주어진 확률 분포에 따라 샘플링\n",
    "p = [0.5, 0.1, 0.05, 0.2, 0.05, 0.1] # 합이 1.0\n",
    "print(sum(p)) # 1.000\n",
    "np.random.choice(words, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76528558 0.39518322 0.03162278]\n",
      "[0.64196878 0.33150408 0.02652714]\n"
     ]
    }
   ],
   "source": [
    "# 네거티브 샘플링에서는 기본 확률 분포에 0.75를 제곱해준다\n",
    "p = [0.7, 0.29, 0.01]\n",
    "new_p = np.power(p, 0.75) # 확률분포 값들에 모두 0.75제곱 처리 ==> 원래 확률이 낮은 단어를 버리지 않기 위해서\n",
    "print(new_p)\n",
    "new_p /= np.sum(new_p) # 다시 전체 요소의 합으로나우어 각 요소의 합이 1.0이 나오도록 새로운 확률 분포를 만든다\n",
    "print(new_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 16\n"
     ]
    }
   ],
   "source": [
    "print(2**4, np.power(2,4) ) # 2^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3개의 긍정 unigram 타겟을 주면  부정 맥락 2개씩 3개 생성해주는 클래스  \n",
    "# nn_layers.py에 추가하여 놓는다\n",
    "\n",
    "import collections\n",
    "class UnigramSampler:\n",
    "    def __init__(self, corpus, power, sample_size): # power= 0.75, sample_size = 2\n",
    "        self.sample_size = sample_size\n",
    "        self.vocab_size = None\n",
    "        self.word_p = None\n",
    "\n",
    "        # corpus 내의 단어별 발생횟수를 구함    \n",
    "        counts = collections.Counter()  \n",
    "        for word_id in corpus:   # corpus: [0 1 2 3 4 1 5 6], \n",
    "            counts[word_id] += 1\n",
    "\n",
    "        vocab_size = len(counts)\n",
    "        self.vocab_size = vocab_size  # 7\n",
    "\n",
    "        self.word_p = np.zeros(vocab_size)  # (7,)\n",
    "        for i in range(vocab_size):  # 7 \n",
    "            self.word_p[i] = counts[i]  # [1, 2, 1, 1, 1, 1, 1] ,단어 발생 횟수\n",
    "\n",
    "        self.word_p = np.power(self.word_p, power) # 0.75제곱\n",
    "        self.word_p /= np.sum(self.word_p)  # 전체의 합으로 나누어 확률을 구함\n",
    "\n",
    "    def get_negative_sample(self, target):   # target = np.array([1, 3, 0]), (3,)\n",
    "        batch_size = target.shape[0]  # 3\n",
    "        \n",
    "        negative_sample = np.zeros((batch_size, self.sample_size), dtype=np.int32)  # (3,2)\n",
    "\n",
    "        for i in range(batch_size):  # 2회\n",
    "            p = self.word_p.copy()\n",
    "            target_idx = target[i]  # 1,3,0\n",
    "            p[target_idx] = 0  # p[1]=p[3]=p[0]=0\n",
    "            p /= p.sum()\n",
    "            negative_sample[i, :] = np.random.choice(self.vocab_size, size=self.sample_size, replace=False, p=p)\n",
    "            \n",
    "        return negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'l': 3, 'o': 2, 'h': 1, 'e': 1, ' ': 1, 'w': 1, 'r': 1, 'd': 1})\n",
      "Counter({'a': 4, 'f': 4, 'b': 3, 'e': 3, 'g': 3, 'c': 2, 'd': 1})\n",
      "Counter({1: 2, 0: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})\n",
      "corpus: [0 1 2 3 4 1 5 6]\n",
      "**before: 0 0\n",
      "   after: 0 1\n",
      "**before: 1 0\n",
      "   after: 1 1\n",
      "**before: 2 0\n",
      "   after: 2 1\n",
      "**before: 3 0\n",
      "   after: 3 1\n",
      "**before: 4 0\n",
      "   after: 4 1\n",
      "**before: 1 1\n",
      "   after: 1 2\n",
      "**before: 5 0\n",
      "   after: 5 1\n",
      "**before: 6 0\n",
      "   after: 6 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 1, 1: 2, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collections.Counter어떤 단어가 주어졌을 때 단어에 포함된 각 알파멧의 글자 수를 dict로 세어주는 클래스\n",
    "# https://www.daleseo.com/python-collections-counter/\n",
    "import collections\n",
    "print(collections.Counter('hello world'))\n",
    "print(collections.Counter('aaaabbbccdeeeffffggg'))\n",
    "\n",
    "corpus = np.array([0, 1, 2, 3, 4, 1, 5, 6])\n",
    "print(collections.Counter(corpus))\n",
    "\n",
    "# corpus 내의 단어별 발생횟수를 구함\n",
    "counts = collections.Counter()\n",
    "print('corpus:',corpus)\n",
    "corpus = np.array([0, 1, 2, 3, 4, 1, 5, 6])\n",
    "for word_id in corpus:\n",
    "    print('**before:',word_id,counts[word_id])\n",
    "    counts[word_id] += 1\n",
    "    print('   after:',word_id,counts[word_id])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정(yes) : [1 3 0]\n",
      "부정(No)  :\n",
      " [[0 4]\n",
      " [2 0]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "corpus = np.array([0, 1, 2, 3, 4, 1, 2, 3])\n",
    "power = 0.75\n",
    "sample_size = 2\n",
    "\n",
    "sampler = UnigramSampler(corpus, power, sample_size)\n",
    "target = np.array([1, 3, 0])\n",
    "negative_sample = sampler.get_negative_sample(target)\n",
    "\n",
    "print('긍정(yes) :' ,target)\n",
    "print('부정(No)  :\\n',negative_sample)  # 실행 시마다 다름\n",
    "\n",
    "# [[4 2]  ==> 첫번째 데이터 1의 부정적 예 2개를 샘플링\n",
    "#  [2 4]  ==> 두번째 데이터 3의 부정적 예 2개를 샘플링\n",
    "#  [1 3]] ==> 세번째 데이터 0의 부정적 예 2개를 샘플링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네거티브 샘플링 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SigmoidWithLoss 클래스 사용 \n",
    "# nn_layers.py 에 추가한다\n",
    "\n",
    "class SigmoidWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.loss = None\n",
    "        self.y = None  # sigmoid의 출력\n",
    "        self.t = None  # 정답 데이터\n",
    "\n",
    "    def cross_entropy_error(self,y, t):\n",
    "        if y.ndim == 1:\n",
    "            t = t.reshape(1, t.size)\n",
    "            y = y.reshape(1, y.size)\n",
    "\n",
    "        # 정답 데이터가 원핫 벡터일 경우 정답 레이블 인덱스로 변환\n",
    "        if t.size == y.size:\n",
    "            t = t.argmax(axis=1)\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "\n",
    "        return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = 1 / (1 + np.exp(-x))   # sigmoid \n",
    "\n",
    "        self.loss = self.cross_entropy_error(np.c_[1 - self.y, self.y], self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "\n",
    "        dx = (self.y - self.t) * dout / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# np.c_()  # c_: column으로 합치기\n",
    "# https://rfriend.tistory.com/tag/np.c_%20%ED%95%A8%EC%88%98\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# N = 3\n",
    "# A = np.eye(N)\n",
    "# print('A:\\n', A)\n",
    "# B = np.c_[A, A[2]]\n",
    "# print('B:\\n', B)\n",
    "\n",
    "A = [1,2,3]\n",
    "B = [4,5,6]\n",
    "C = np.c_[A,B]\n",
    "print(C)\n",
    "\n",
    "R = np.r_[A,B]  # r_: row로 합치기\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NegativeSamplingLoss 클래스\n",
    "# nn_layers에 추가하여 놓는다\n",
    "\n",
    "class NegativeSamplingLoss:\n",
    "    def __init__(self, W, corpus, power=0.75, sample_size=5):  #  sample_size : 부정적 예 샘플링 수 (2개)\n",
    "        self.sample_size = sample_size\n",
    "        self.sampler = UnigramSampler(corpus, power, sample_size)\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size + 1)]     # 3개층, 긍정 1층 + 부정 2층\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size + 1)]  # 3개층, 긍정 1층 + 부정 2층\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.embed_dot_layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, h, target): # h: 은닉층 뉴런수, target은 긍정적 예의 target\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_negative_sample(target) # 부정적 예\n",
    "\n",
    "        # 긍정적 예 순전파\n",
    "        score = self.embed_dot_layers[0].forward(h, target)\n",
    "        correct_label = np.ones(batch_size, dtype=np.int32)  # 값이 모두 1 : 긍정\n",
    "        loss = self.loss_layers[0].forward(score, correct_label)\n",
    "\n",
    "        # 부정적 예 순전파\n",
    "        negative_label = np.zeros(batch_size, dtype=np.int32) # 값이 모두 0 : 부정\n",
    "        for i in range(self.sample_size):\n",
    "            negative_target = negative_sample[:, i]\n",
    "            score = self.embed_dot_layers[1 + i].forward(h, negative_target)\n",
    "            loss += self.loss_layers[1 + i].forward(score, negative_label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1): # 입력값을 각 계층의 backward만 호출하여 전달\n",
    "        dh = 0\n",
    "        for l0, l1 in zip(self.loss_layers, self.embed_dot_layers): # 역전파이므로  los_layer가 먼저 호출된다\n",
    "            dscore = l0.backward(dout) # SigmoidWithLoss 계층\n",
    "            dh += l1.backward(dscore)  # EmbeddingDot 계층\n",
    "\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<__main__.SigmoidWithLoss at 0x20d345ff208>,\n",
       "  <__main__.SigmoidWithLoss at 0x20d31bcdf88>,\n",
       "  <__main__.SigmoidWithLoss at 0x20d345ff5c8>],\n",
       " [<__main__.EmbeddingDot at 0x20d345ef088>,\n",
       "  <__main__.EmbeddingDot at 0x20d345ef148>,\n",
       "  <__main__.EmbeddingDot at 0x20d345efe88>])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.random.randn(7, 3)\n",
    "neg = NegativeSamplingLoss(W, corpus,0.75,2)\n",
    "neg.loss_layers, neg.embed_dot_layers  # 각각 3개씩 생성 되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
